# 隐私计算&联邦学习综述

>  各位老师、领导、同事、同学大家好，今天由我来给大家做一个隐私计算和联邦学习相关的综述，目前我在这块的了解还是比较粗浅的，不过已经尽自己最大的努力去学习了，如果有任何问题，欢迎大家指正！

## 隐私计算

首先在中国科学院信息工程研究所，李风华的这篇《隐私计算研究范畴及发展趋势》当中，给出的隐私定义是这样的`[...]`

在另一篇论文《隐私计算发展综述》中，给出的隐私计算定义是`[...]`

**总结来说，隐私计算是一门保护用户隐私、融合交叉学科的技术。**

- 隐私计算涵盖了信息搜集者、发布者和使用者在信息产生、感知、发布、传播、存储、 处理、使用、销毁等全生命周期过程的所有计算操作，并包含支持海量用户、高并发、高效能隐私保护的系统设计理论与架构。

## 隐私计算的分类

这篇中国信通院大数据研究所的《隐私计算发展综述》，将隐私计算分为密码学和可信硬件两大领域。

- 可信硬件领域则主要指可信执行环境；

- 其中密码学技术主要以安全多方技术为代表；

  此外，还有基于以上两种技术路径衍生出的联邦学习（可以理解为一种保护用户隐私的机器/深度学习）。

## 可信执行环境

可信执行环境的代表性硬件产品主要有Intel的 SGX、ARM 的 TrustZone 等，由此也诞生了很多基于以上产品的商业化实现方案，如百度 MesaTEE、华为iTrustee等。

可信执行环境技术具备更好的性能和算法适用性，但是对于硬件的局限及国外芯片的强依赖，使得其在国内的产品选型相对较少，较集中于百度、阿里等互联网大厂在使用。

## 安全多方计算

> 安全多方计算MPC是密码学的一个子领域，目的是多个参与方协同地从每一方的隐私输入中计算某个函数的结果，从而不用将这些输入数据展示给其他方。

最初针对的是一个安全两方计算问题，也就是即著名的百万富翁问题：

**两个百万富翁都想要比较到底谁更加富有，但是又都不想让别人知道自己有多少钱。如何在一个没有可信的第三方的情况下解决这个问题？**

当前主要有三种方式可以用来实现安全多方计算：**不经意传输、秘密共享、混淆电路**

### 不经意传输

不经意传输中，发送方拥有一个“消息-索引”对(M1,1),...,(Mn,n),在每次传输时，接收方选择一个索引k（0～n），并接受Mk。接收方不能得知除了Mi以外的任何信息，发送方也不能了解接收方选择的具体哪个索引对的信息。

在实际使用中，不经意传输的一种实施方式时基于RSA公钥加密技术的。

- 发送方生成两对不同的公私钥，并公开两个公钥`pk1`和`pk2`。
- 假设接收方希望收到消息M1，但不希望发送方知道他想要收到的消息时M1。接收方随机生成一个随机数k，再用公钥pk1对k进行加密，并传输给发送方。
- 发送方用两个私钥对加密后的k进行解密，私钥sk1解密得到k1，私钥sk2解密得到k2。（只有k1等于k，k2时一个无意义的数字）。但发送方并不知道哪个是真正的k
- 发送方把m1和k进行异或，把m2和k2进行异或，并把两个异或的结果都发送给接收方
- 接收方使用k与收到的消息进行异或。接收方只能算出m1，而无法推测出m2。因为接收方无法知道私钥sk2，从而推不出k2的值，而且发送方也不知道接收方能算出哪个消息。
- 接收方可以进一步通过CRC校验来确定m1是正确收到的消息。

### 秘密共享

通过将原始秘密值A分割为随机多份，比如分割成n份，记为x1,x2,...,xn，并将这些份分发给n个不同的参与方。当且仅当足够数量（比如至少t个）的秘密值组合在一起时，才能够重新构造被共享的秘密，而任意的t-1个秘密值都不能重构原始数据。

### 混淆电路

中心思想是将计算电路分解为产生阶段和求值阶段。两个参与方各自负责一个阶段，而在每一阶段中电路都被加密处理，所以任何一方都不能从其他方获取信息，但仍然可以根据电路获取结果。

### Python安全计算库

以上的一些方法在密码学领域已经被广泛研究和使用，因此当前也有很多开源的实现方案可供使用。这里是一些Python计算库和框架。

## 联邦学习定义

> 然后我们看一下隐私计算下面的第三类：联邦学习

在模型训练过程中，模型的相关信息（如模型参数、模型结构、参数梯度等）能够在各参与方之间交换，但本地训练数据**不会离开本地**。

联邦学习的概念曾多次以不同形式出现过，早在 2012 年即有学者发表了基于数据隐私保护的分布式机器学习相关研究成果，直到 2016 年谷歌率先提出联邦学习的概念，才逐步受到更广泛的关注 。

#### google app

问题：google想要利用用户的手机数据训练模型，但是由于法律和隐私保护的问题，用户并不想要上传自己的数据到云端服务器。

#### 医疗

问题：各家医院想要用医疗数据训练一个模型，利用这些模型做智能诊断和预测，每家医院都有自己的数据可以训练模型，但是每家的数据不够多，训练出来的效果不够好。把医院换成银行保险公司也是一样的道理。但是各家机构由于法律和公司的规定，不允许把数据泄露出去。

## 联邦学习分类

#### 根据特征空间

- 横向联邦学习：适用于联邦学习的参与方的数据有重叠的数据特征，即数据特征在参与方之间是对齐的，但是参与方拥有的数据样本是不同的。**它类似于在表格视图中将数据水平划分的情况。**例如，有两家服务于不同地区的银行，它们虽然可能只有很少的重叠客户，但是客户的数据可能因为相似的商业模式而有相似的数据特征，也就是两家银行的用户群体集合重叠部分小，但是在数据特征维度上重叠部分较大。两家银行就可以通过横向联邦学习共同建立一个机器学习模型，更好地为客户推荐理财产品。
- 纵向联邦学习：适用于联邦学习参与方的数据特征上有所不同，训练数据的数据样本的有重叠的情况。**它类似于数据在表格视图中将数据垂直划分的情况。**例如两家公司提供不同的服务，一家银行和一家电子商务公司，在客户群体上有非常大的交集，可以在各自的不同数据特征空间上协作。在电子商务公司我们预测用户对某一个物品的购买概率，但通常电子商务公司只有用户购买行为信息，而银行等金融机构有用户的资产数据，这部分特征能很好提现用户的消费水平，如果能补充这部分特征到推荐模型中，将极大提升模型预测能力。
- 联邦迁移学习适用于参与方的数据样本和数据特征重叠都很少的情况。

#### 根据协调方式

- 一般存在一个中心计算方，该中心计算方承担收集其他各方传递的模型参数信息并经过相应算法更新后返回各方，较易于设计和实现。
- 不存在中心节点，可以防止由于中心节点存在隐私泄露和遭受恶意攻击的情况，这种设计更加安全但是实现难度较大

## 分布式机器学习

> 联邦学习本质上也是一种分布式机器学习。

想要让算法收敛，需要重复很多轮梯度下降，每一轮中一共需要两次通信。

## 联邦学习和分布式机器学习的区别

- 用户对自己的设备由绝对的控制权，用户可以随时让自己的设备停止参与计算和通信，这就像是联邦的组成部分，每一个邦都有高度的自治权；而传统的分布式机器学习中，worker收到server的控制并接受指令。
- 参与联邦学习的节点大多是手机、ipad等不稳定的设备，而传统分布式机器学习的设备都是在机房里连着高速宽带24小时机器，有专人维护，非常稳定。
- 联邦学习不同设备之间的计算性能差异性也非常大，而分布式机器学习的节点计算性能都是差不多的。
- 联邦学习主要的瓶颈在于通信，通信代价远大于计算代价。
- 联邦学习的数据并非独立同分布
- 节点数量的数量级也是完全不一样的。

总结：虽然联邦学习是一种分布式机器学习，但是联邦学习有很多独特的问题和难点，导致建模和计算都很麻烦。

## 非独立同分布

`[...]`

## 联邦平均算法

> 这边介绍一种横向联邦学习里面应用非常普遍的联邦平均算法。

由于联邦学习中存在：数据非独立同分布、数据量不平横、参与方数量大、通信效率低这些情况。由于前三者我们是无法改变的客观条件，所以通信效率这一个重要瓶颈就成为了这个算法的切入点。

**这边搞清楚联邦平均和分布式机器学习的区别！**

在worker节点进行很多次epoch，而不是一次epoch就发送给server，从而提高通信效率。

## 安全联邦平均算法

联邦平均算法+同态加密

## 联邦学习可以研究的方向

### 隐私保护

比如用户的肖像数据，虽然不能推断出用户的肖像，但是能获得他是男是女，是白人还是黑人等信息。

- 差分隐私：有方法往数据里面加噪声，但也是不可行的，大大影响了模型收敛的速度和效果。加噪声收敛速度和准确度都会变差，加的噪声越多，机器学习的效果越差，加噪声测试的准确度可能会掉几个百分点，这在工业界是很难接受的。
  - 孩子蹬被子怎么办，把孩子腿打断就不会蹬被子了，隐私是被保护了，但是模型也学不好，孩子是不蹬被子了，但是腿也被打断了。

- 同态加密：在密文上计算的结果（例如加减乘除四则运算）在被解密后与在明文上的计算结果相匹配，就如同对明文执行了一样的操作计算。

### 通信效率

#### 联邦平均

- 以通信次数为横轴，FedAvg用更小的通信次数，达到更小的Loss，也就是收敛的更快
- 以epoch（用于衡量计算量）为横轴，让Worker节点做相同的计算量，FedAvg的收敛更慢

天下没有免费的午餐，FedAvg减少了通信量，但是增加了Worder节点的计算量，牺牲计算量为代价，换取通信量。因为联邦学习中计算代价小，通信代价大，所以这种算法是合理的。

#### 模型压缩

- **量化方法**：降低更新参数的“分辨率”，如：整数化，二值化
- **稀疏化**：稀疏模型将大量的冗余变量去除，只保留与响应变量最相关的内容。

- **知识蒸馏**：做法是先训练一个teacher网络，然后使用这个teacher网络的去训练student网络。可以用来将网络从大网络转化成一个小网络，并保留接近于大网络的性能；

### 鲁棒性

文章1:把一部分作为训练数据的图片做一些小幅度修改，但这些修改是精心设计出来的扰动，这些图片就变成了毒药，可以用来对模型下毒，如果训练模型的时候用到这种毒药，模型就会出现很奇怪的错误，这篇文章是适用于普遍的深度学习的，如果把这种攻击用到联邦学习上，这是很容易做到的。worker节点上将自己的数据做一些修改，上传到server服务器上。

文章2:把本地的数据标签换成错误的，用正确的图片和错误的标签计算梯度方向，再把梯度方向发送给server。



Denfense1: Server检验模型梯度到底好不好，Server会拿某个Worker传回来的梯度更新模型参数，然后算一下用新的参数在测试集合上的效果好不好，如果某个worker传回恶意梯度肯定会造成准确度的下降。但这种防御其实不适用于联邦学习，因为联邦学习的梯度是非独立同分布的，就算是诚实的worker节点也有可能造成准确下降，只有把所有的worder传回来的模型进行平均才能得到最终的模型。

Denfense2: 如果假设数据是独立同分布，所有worker的梯度都不会差太远，我们可以计算模型的欧式距离，要是个别梯度和所有的梯度差别很大，就可以认为worker是异常的。但数据不是独立同分布的！

文章3、4、5：Server不是对所有worker的梯度做加权平均，而是用一些更稳定的方式来整合梯度，比如说把平均换成中位数等方式，但也有可能不成立，这些文章也都在假设数据是独立同分布的。

总而言之，攻击很容易，但是防御很困难！

### 区块链+联邦学习

- 采用去中心化区块链取代联邦学习中的中央服务器Server，克服中央服务器单点信任及故障问题。
- 结合区块链的不可篡改性，将参与方数据和模型参数上链，防止数据篡改。
- 结合共识机制和智能合约，利用区块链实现激励机制，实行收益自动分配



- 利用**区块链**赋予边缘节点防篡改和抗单点故障攻击等特性，并在**共识协议中融入梯度验证和激励机制**，鼓励更多的本地设备诚实地向联邦学习贡献算力和数据。

## 应用场景

目前联邦学习主要的应用场景是金融、医疗领域



### 智慧城市

智慧城市在经历了短暂爆发后，智慧城市发展进入了一个瓶颈期，城市建设面临诸多严峻的挑战：

- **强调技术而忽视参与**。强调大型企业单位的信息化和平台建设，忽略小型企业的参与程度

- **数据孤岛和数据碎片**。城市管理中的数据整合缺失问题依旧没有解决

- **智能系统的安全风险**。对于信息安全、运营安全、网络安全的重视不够，增加了城市管理的成本和风险。
- **缺乏可持续的经营模式**。市场参与机制不够全面。需要建立可持续、公平公正、受市场规则约束的收益共享和奖励机制。

具有协作型和隐私保护性的联邦学习可以解决城市计算和智慧城市所遇到的问题。

比如在智慧住区建设当中，建设可信数据服务基础网络、强化各部门数据要素供给、提供基础数据服务能力、建立数据授权使用机制当中都可以发挥价值。

### 房产监管平台

在搭建可信房地产数据网络、建立房地产数据中枢体系、保护市场主体相对独立权益、优化安全隐私防护能力也可以有所作为。

