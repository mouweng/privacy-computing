# 联邦学习

- [联邦学习FAQ](https://github.com/tao-shen/Federated-Learning-FAQ/)

- [Federated-Learning-FAQ-浙大CS博士解读联邦学习](https://www.bilibili.com/video/BV1mE411j7GT?spm_id_from=333.337.search-card.all.click)

## 概念

### 1 什么是联邦学习

联邦学习（FL）是一种机器学习设定，其中许多客户端（例如，移动设备或整个组织）在中央服务器（例如，服务提供商）的协调下**共同训练模型**，同时保持训练数据的**去中心化及分散性**。

联邦学习的**长期目标**：在不暴露数据的情况下分析和学习多个数据拥有者的数据。（目的：解决数据孤岛）

![](https://cdn.jsdelivr.net/gh/mouweng/FigureBed/img/202204241056024.png)

### 2 为什么叫“联邦”学习？有什么特点？

因为学习任务是通过由中央服务器协调的参与设备（客户端）的松散联邦来解决的。**不均衡和Non-IID**（非独立同分布）的数据分隔通过大量**不可靠的设备**，并且是**有限的通信带宽**，这是作为引入的挑战。

## 3 为什么要引入“联邦学习”这个概念？

大量工作试图使用中央服务器在**保护隐私的同时从本地数据中学习**。目前没有任何一项工作可以直接解决FL定义下的全部挑战。“联邦学习”这个词为这一系列特征，约束和挑战**提供了便捷的简写**，这些约束和挑战通常在隐私至关重要的机器学习问题中同时出现。

### 4 联邦学习的场景与分类？

联邦学习根据不同场景可以分为两大类：“**跨设备**”和“**跨孤岛**”。

- **跨设备**：Gboard移动键盘

- **跨孤岛**：医疗数据联邦学习

|          | 跨孤岛             | 跨设备               |
| -------- | ------------------ | -------------------- |
| 例子     | 医疗机构           | 手机端应用           |
| 节点数量 | 1~100              | 1~10^10              |
| 节点状态 | 节点几乎稳定运行   | 大部分节点不在线     |
| 主要瓶颈 | 计算瓶颈和通信瓶颈 | WiFi速度，设备不在线 |
| Yang分类 | 横向/纵向          | 横向                 |

### 5 联邦学习有什么经典的优化算法？

#### 联邦平均算法（FedAvg）

![](https://cdn.jsdelivr.net/gh/mouweng/FigureBed/img/202204241104057.png)

1. **客户端选择**：服务器从一组符合资格要求的客户端中采样。例如，为避免影响设备用户，移动电话可能仅在未计量的wi-fi连接上插入且处于空闲状态时才签入服务器。

2. **传播：** 选定的客户端从服务器下载当前模型权重和训练程序。
3. **客户端计算：** 每个选定的设备都通过执行训练程序在本地计算对模型的更新，例如，可以在本地数据上运行SGD。
4. **聚合：** 服务器收集设备更新的汇总。为了提高效率，一旦有足够数量的设备报告了结果，用户就可以在此处放散手。此阶段也是许多其他技术的集成点，这些技术将在后面讨论，可能包括：用于增加隐私的安全聚合，为了通信效率而对聚合进行有损压缩，以及针对差分隐私的噪声添加和更新限幅。
5. **模型选择：** 服务器根据从参与当前轮次的客户端计算出的聚合更新在本地更新共享模型。

### 6 联邦学习和一般分布式机器学习的主要区别？

|          | 分布式训练                                           | **联邦学习**                                                 |
| -------- | ---------------------------------------------------- | ------------------------------------------------------------ |
| 数据分布 | 集中存储不固定，可以任意打乱、平衡地分配给所有客户端 | 分散存储且固定，数据无法互通、可能存在数据的Non-IID（非独立同分布） |
| 节点数量 | 1~1000                                               | 1~10^10                                                      |
| 节点状态 | 所有节点稳定运行                                     | 节点可能不在线                                               |

- [什么是非独立同分布（Non-IID）数据，有没有很简单的解释方法？](https://www.zhihu.com/question/395555567)

### 7 数据集中式分布式学习与跨孤岛/跨设备联邦学习的综合对比？

|              | 数据集中式的分布式学习                                       | 跨孤岛的联邦学习                                             | 跨设备的联邦学习                                             |
| ------------ | ------------------------------------------------------------ | ------------------------------------------------------------ | ------------------------------------------------------------ |
| 设置         | 在大型但“扁平”的数据集上训练模型。客户端是单个群集或数据中心中的计算节点。 | 在数据孤岛上训练模型。客户是不同的组织（例如，医疗或金融）或地理分布的数据中心。 | 客户端是大量的移动或物联网设备                               |
| 数据分布     | 数据被集中存储，可以在客户端之间进行混洗和平衡。任何客户端都可以读取数据集的任何部分。 | 数据在本地生成，并保持分散化。每个客户端都存储自己的数据，无法读取其他客户端的数据。数据不是独立或相同分布的。 | 与跨孤岛的数据分布一样                                       |
| 编排方式     | 中央式编排                                                   | 中央编排服务器/服务负责组织培训，但从未看到原始数据。        | 与跨数据孤岛编排方式一样                                     |
| 广域通讯     | 无（在一个数据中心/群集中完全连接客户端）。                  | 中心辐射型拓扑，中心代表协调服务提供商（通常不包含数据），分支连接到客户端。 | 与跨孤岛的广域通讯方式一样                                   |
| 数据可用性   | 所有客户端都是可用的                                         | 所有客户端都是可用的                                         | 在任何时候，只有一小部分客户可用，通常会有日间或其他变化。   |
| 数据分布范围 | 通常1-1000个客户端                                           | 通常2~1000个客户端                                           | 大规模并行，最多10^10个客户端。                              |
| 主要瓶颈     | 在可以假设网络非常快的情况下，计算通常是数据中心的瓶颈。     | 可能是计算和通信量                                           | 通信通常是主要的瓶颈，尽管这取决于任务。通常跨设备联邦学习使用wifi或更慢的连接。 |
| 可解决性     | 每个客户端都有一个标识或名称，该标识或名称允许系统专门访问它。 | 与数据集中式的分布式学习一样                                 | 无法直接为客户建立索引（即不对用户进行标记）。               |
| 客户状态     | 有状态的-每个客户都可以参与到计算的每一轮中，不断地传递状态。 | 有状态的-每个客户都可以参与到计算的每一轮中，不断地传递状态。 | 高度不可靠-预计有5％或更多的客户端参与一轮计算会失败或退出（例如，由于违反了电池，网络或闲置的要求而导致设备无法使用）。 |
| 客户可靠性   | 相对较少的失败次数                                           | 相对较少的失败次数。                                         | 无状态的-每个客户在一个任务中可能只参与一次，因此通常假定在每轮计算中都有一个从未见过的客户的新样本。 |
| 数据分区轴   | 数据可以在客户端之间任意分区/重新分区。                      | 固定分区。能够根据样本分区（横向）或者特征分区（纵向）。     | 根据样本固定分区（横向）。                                   |

## 存在的问题（20.03）

### 联邦学习主要面临哪些挑战？

- 非独立同分布non-IID数据和不平衡的数据
- 有限的通信带宽
- 不可靠和有限的可用设备

### 什么是Non-IID非独立同分布数据？

#### **不同客户端数据分布不同**

- 特征分布倾斜（手写识别问题，不同人笔迹不同）
- 标签分布倾斜（企鹅只在南极，北极熊只在北极）
- 标签相同特征不同（概念飘逸，和4相对）
- 特征相同标签不同（比如正常人点头Yes，摇头No，但是在一些稀少部落里面相反）
- 数量不平衡

#### 数据偏移

训练集测试集不同分布，比如大部分都是狗在草地上跑的图片进行训练，有一天你给了一个河里游泳的狗，就识别不出来。

#### 非独立

可用节点大多在相同的地理位置（比如人在睡觉的时候网络稳定，可能会选取一个时区的设备）

### 处理Non-IID数据有什么策略？

- 修改现有的算法
- 创建一个可以全局共享的小数据集（有一部分公共数据集）
- 不同客户端提供不同的模型（Non-IID变成一种特性）

